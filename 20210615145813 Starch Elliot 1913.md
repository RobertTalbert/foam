# Starch Elliot 1913

#grading #masterygrading 

>Starch, D., & Elliott, E. C. (1913). Reliability of grading work in mathematics. The School Review, 21(4), 254-259.

## Questions and Focus 

1. How fine of a scale should we be using for grades? ("How fine of a scale of units is distinguishable")
2. What proportion of students will usually fall under each unit? 

+ Fineness of scale
    + For example, does it make sense to use a 0-100 scale for markings? Why not a 0.0-100.0 scale (go finer)? Is a scale with just four units too coarse? 
    + 

## Methods

### Fineness of scale

- Looked at two English papers from 142 teachers 
- Grades ranged from 64 to 98 on one paper, 50 to 98 on the other "probable error" of 4.0 and 4.8 respectively
- Also a paper in math, 118 teachers, grades range from 28 to 92 with probable error of 7.5
- Four main factors in the variation of these marks: 
    - Differences in standards among different schools
    - Differences among standards with different teachers
    - Differences in relative values placed by different teachers on different elements of the papers (i.e. differences in rubrics) 
    - Differences due to inability to disinguish between "closely allied degrees of merit" 

- Factors 1 and 2: Differences among schools and instructors 
    - Looked at 10 papers written in final exam of freshman English at University of Wisconsin, each graded by 10 different instructors 
    - Results: A wide range of marks – average of mean variations was 5.3 
    - Variation was consistent except in a couple of cases where it was even greater – the grades on those was below passing on average. Once a paper is seen as "failing" then the grade variances get really big probably because it doesn't really matter what the mark is, it's failing, so less care is taken to be consistent (or fair). 
    - Also teachers who actually had the students in class, didn't grade any more accurately than those who didn't know the students at all
    - To adjust for instructor variation, scores were statistically weighted by amount that instructor average differed from general average (e.g. convert to a $z$-score). **Results:** Not much change in variation, 4.3 vs 5.3.  
- Factor 3: Inability to distinguish between close shades of merit 
    - Give the same person two or more evaluations of the same papers separated by a long period of time (to forget the details and identity of the paper)
    - Results: Difference between grading sessions is average 4.4 points (2.2 "in terms of mean variation")
    - One math instructor had much lower variation (2.1 points versus 7.8 points for the other math instructor) – that instructor used a rubric where the other did not. --> Doesn't mean the grading is good, just less variation. 

## Findings 

- Of the four factors: 
    - General mean variation or probable error of grades assigned by teachers in different schools is 5.4 points
    - Mean variation of grades assigned by teachers in the same department is 5.3 points. 
    - Therefore factor 1 doesn't really count for anything – negligible differences between schools. [^1]
    - Mean variation after eliminating effect of personal standards of teachers is 4.3. 
    - Mean variation in grades assigned at different times by same teachers to their own papers is 2.2 
    - Therefore the remaining 2.1 points of variation comes from inability to distinguish between fine shades of merit. 
    

## Interpretations

- Units of any scale of measurement should be such that ¾ of all measurements of the same quantity should fall within the limits of one division of the scale. (*Where does this come from? There's no reference attached.*)
- Put differently a unit of division on a scale should be the interval in whih 75% of the results fall ("...if the marks assigned by 75 out of 100 teachers to a given paper lie between 80 and 90, then the unit of our scale should be ten points")
- After eliminating differences in personal standard, mean variation for a teacher is 1.75 points. 
- Therefore the smallest step that can be used with reasonable validity is "2 ¾ times the mean variation.… which would be 4.8 or roughly 5 points."
- So, in the range of passing grades, there should not be 30 points (70-100) but 6 divisions, roughly corresponding to A+, A-, B+, B-, ..., D-. *And no plain letters!* 
- A better scale might be obtained using the mean variation of 4.3 points, which gives a scale broken up into $4.3 \times 2 \frac{3}{4} \approx 12$ points each. So just three passing grades: A, B, and C plus a failing grade. *Note: Roughly the same thing as EMRN.* 
- Objections to a finer scale: 
    - "An illusion of accuracy" (ouch!)
    - "Injustice to the student" due to error from inability to distinguish fine shades
    - "Embarrassment to the teacher due to this injustice"
- Using a fine scale is like trying to estimate the length of a number of irregular wooden rods by using inches as the units. Leads to wide variability. In fact the authors did this – used rods of lengths 5 inches to 23 inches and had professional carpenters estimate the lengths, and the mean variations were very similar to the variations in the grades given to the papers earlier in the study. 

—

[^1]: Which schools did they look at? Were there a lot of variations in school type or did they look at just different kinds of schools in the same category? 